{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Analysis NYC TLC Trips Records Data Feb 2021\n",
    "---\n",
    "<sub>Muhammad Difagama Ivanka</sub>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(233)\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName('nyc_spark') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 20.7M    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  1 20.7M    1  326k    0     0   140k      0  0:02:31  0:00:02  0:02:29  140k\n",
      " 12 20.7M   12 2737k    0     0   841k      0  0:00:25  0:00:03  0:00:22  842k\n",
      " 17 20.7M   17 3655k    0     0   859k      0  0:00:24  0:00:04  0:00:20  859k\n",
      " 17 20.7M   17 3767k    0     0   704k      0  0:00:30  0:00:05  0:00:25  760k\n",
      " 19 20.7M   19 4068k    0     0   650k      0  0:00:32  0:00:06  0:00:26  829k\n",
      " 20 20.7M   20 4416k    0     0   605k      0  0:00:35  0:00:07  0:00:28  821k\n",
      " 22 20.7M   22 4832k    0     0   579k      0  0:00:36  0:00:08  0:00:28  411k\n",
      " 25 20.7M   25 5326k    0     0   575k      0  0:00:36  0:00:09  0:00:27  334k\n",
      " 27 20.7M   27 5763k    0     0   562k      0  0:00:37  0:00:10  0:00:27  406k\n",
      " 38 20.7M   38 8134k    0     0   722k      0  0:00:29  0:00:11  0:00:18  812k\n",
      " 45 20.7M   45 9724k    0     0   777k      0  0:00:27  0:00:12  0:00:15 1019k\n",
      " 61 20.7M   61 12.8M    0     0   993k      0  0:00:21  0:00:13  0:00:08 1696k\n",
      " 73 20.7M   73 15.3M    0     0  1101k      0  0:00:19  0:00:14  0:00:05 2075k\n",
      " 85 20.7M   85 17.8M    0     0  1195k      0  0:00:17  0:00:15  0:00:02 2494k\n",
      " 97 20.7M   97 20.2M    0     0  1275k      0  0:00:16  0:00:16 --:--:-- 2519k\n",
      "100 20.7M  100 20.7M    0     0  1292k      0  0:00:16  0:00:16 --:--:-- 2925k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      " 15 1118k   15  174k    0     0   112k      0  0:00:09  0:00:01  0:00:08  112k\n",
      "100 1118k  100 1118k    0     0   490k      0  0:00:02  0:00:02 --:--:--  492k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 10.1M    0 16384    0     0  14415      0  0:12:18  0:00:01  0:12:17 14422\n",
      " 10 10.1M   10 1070k    0     0   502k      0  0:00:20  0:00:02  0:00:18  502k\n",
      " 34 10.1M   34 3570k    0     0   895k      0  0:00:11  0:00:03  0:00:08  896k\n",
      " 34 10.1M   34 3586k    0     0   847k      0  0:00:12  0:00:04  0:00:08  847k\n",
      " 35 10.1M   35 3666k    0     0   695k      0  0:00:14  0:00:05  0:00:09  725k\n",
      " 42 10.1M   42 4380k    0     0   709k      0  0:00:14  0:00:06  0:00:08  866k\n",
      " 63 10.1M   63 6567k    0     0   920k      0  0:00:11  0:00:07  0:00:04 1099k\n",
      " 66 10.1M   66 6946k    0     0   832k      0  0:00:12  0:00:08  0:00:04  773k\n",
      " 67 10.1M   67 7026k    0     0   765k      0  0:00:13  0:00:09  0:00:04  695k\n",
      " 69 10.1M   69 7249k    0     0   708k      0  0:00:14  0:00:10  0:00:04  720k\n",
      " 71 10.1M   71 7409k    0     0   656k      0  0:00:15  0:00:11  0:00:04  592k\n",
      " 73 10.1M   73 7678k    0     0   632k      0  0:00:16  0:00:12  0:00:04  222k\n",
      " 78 10.1M   78 8165k    0     0   620k      0  0:00:16  0:00:13  0:00:03  253k\n",
      " 84 10.1M   84 8790k    0     0   621k      0  0:00:16  0:00:14  0:00:02  355k\n",
      "100 10.1M  100 10.1M    0     0   703k      0  0:00:14  0:00:14 --:--:--  692k\n"
     ]
    }
   ],
   "source": [
    "!curl https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > yellow_tripdata_2021-02.parquet\n",
    "!curl https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-02.parquet > green_tripdata_2021-02.parquet\n",
    "!curl https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2021-02.parquet > fhv_tripdata_2021-02.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = spark.read.parquet('yellow_tripdata_2021-02.parquet')\n",
    "df_green = spark.read.parquet('green_tripdata_2021-02.parquet')\n",
    "df_fhv = spark.read.parquet('fhv_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_data(the_df, pickup_col: str, dropoff_col: str):\n",
    "    pickup_col = F.col(pickup_col)\n",
    "    dropoff_col = F.col(dropoff_col)\n",
    "\n",
    "    the_df = the_df.where((pickup_col >= \"2021-02-01 00:00:00\")\n",
    "    & (pickup_col< \"2021-03-01 00:00:00\"))\n",
    "    the_df = the_df.where((dropoff_col >= \"2021-02-01 00:00:00\"))\n",
    "    return the_df\n",
    "\n",
    "df_yellow = filtered_data(df_yellow, 'tpep_pickup_datetime', 'tpep_dropoff_datetime')\n",
    "df_green = filtered_data(df_green, 'lpep_pickup_datetime', 'lpep_dropoff_datetime')\n",
    "df_fhv = filtered_data(df_fhv, 'pickup_datetime', 'dropOff_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double, RatecodeID: double, store_and_fwd_flag: string, PULocationID: bigint, DOLocationID: bigint, payment_type: bigint, fare_amount: double, extra: double, mta_tax: double, tip_amount: double, tolls_amount: double, improvement_surcharge: double, total_amount: double, congestion_surcharge: double, airport_fee: double] \n",
      "\n",
      "DataFrame[VendorID: bigint, lpep_pickup_datetime: timestamp, lpep_dropoff_datetime: timestamp, store_and_fwd_flag: string, RatecodeID: double, PULocationID: bigint, DOLocationID: bigint, passenger_count: double, trip_distance: double, fare_amount: double, extra: double, mta_tax: double, tip_amount: double, tolls_amount: double, ehail_fee: int, improvement_surcharge: double, total_amount: double, payment_type: double, trip_type: double, congestion_surcharge: double] \n",
      "\n",
      "DataFrame[dispatching_base_num: string, pickup_datetime: timestamp, dropOff_datetime: timestamp, PUlocationID: double, DOlocationID: double, SR_Flag: int, Affiliated_base_number: string]\n"
     ]
    }
   ],
   "source": [
    "print(df_yellow, \"\\n\")\n",
    "print(df_green, \"\\n\")\n",
    "print(df_fhv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How many taxi trips were there on February 15?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yellow Taxi Trips on 15 February 2021\t\t\t: 43734\n",
      "Green Taxi Trips on 15 February 2021\t\t\t: 1798\n",
      "For-Hire Vehicle (FHV) Trips on 15 February 2021\t: 35523\n",
      "All Taxi Total Trips on 15 February 2021\t\t: 81055\n"
     ]
    }
   ],
   "source": [
    "def total_trips_cnt(the_df, pickup_time_col):\n",
    "    trips_cnt = the_df.where((the_df[pickup_time_col] >= \"2021-02-15 00:00:00\")\n",
    "    & (the_df[pickup_time_col] < \"2021-02-16 00:00:00\")).count()\n",
    "    return trips_cnt\n",
    "\n",
    "yel_cnt = total_trips_cnt(df_yellow, 'tpep_pickup_datetime')\n",
    "grn_cnt = total_trips_cnt(df_green, 'lpep_pickup_datetime')\n",
    "fhv_cnt = total_trips_cnt(df_fhv, 'pickup_datetime')\n",
    "\n",
    "print(f\"Yellow Taxi Trips on 15 February 2021\\t\\t\\t: {yel_cnt}\")\n",
    "print(f\"Green Taxi Trips on 15 February 2021\\t\\t\\t: {grn_cnt}\")\n",
    "print(f\"For-Hire Vehicle (FHV) Trips on 15 February 2021\\t: {fhv_cnt}\")\n",
    "print(f\"All Taxi Total Trips on 15 February 2021\\t\\t: {np.sum([yel_cnt,grn_cnt,fhv_cnt])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The longest trip for each day"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Longest Duration (minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration (minutes)\n",
    "def duration_trips_cal(the_df, pickup_col: str, dropoff_col: str, res_name_col = 'Longest Duration (minutes)'):\n",
    "    '''in minute(s)'''\n",
    "    duration_col = 'trip_duration'\n",
    "    date_col = F.to_date(pickup_col)\n",
    "    org_col = 'Pickup Date'\n",
    "\n",
    "    df_temp = the_df.withColumn(\n",
    "        duration_col,\n",
    "        (F.col(dropoff_col).cast('long') - F.col(pickup_col).cast('long'))/60\n",
    "    )\n",
    "    df_temp = df_temp.groupBy(date_col).max(duration_col)\n",
    "    df_temp = df_temp.withColumnRenamed(f'max({duration_col})', res_name_col)\\\n",
    "        .withColumnRenamed(f'to_date({pickup_col})', org_col)\n",
    "    org_col = F.col(org_col)\n",
    "    df_temp = df_temp.orderBy(org_col.asc())\n",
    "    return df_temp\n",
    "\n",
    "N_show, TRCT = 28, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yellow Taxi Trip Records\n",
      "\n",
      "+-----------+--------------------------+\n",
      "|Pickup Date|Longest Duration (minutes)|\n",
      "+-----------+--------------------------+\n",
      "|2021-02-01 |1421.8                    |\n",
      "|2021-02-02 |1438.6666666666667        |\n",
      "|2021-02-03 |1439.45                   |\n",
      "|2021-02-04 |1439.75                   |\n",
      "|2021-02-05 |1439.5833333333333        |\n",
      "|2021-02-06 |1439.0                    |\n",
      "|2021-02-07 |1439.2833333333333        |\n",
      "|2021-02-08 |1439.45                   |\n",
      "|2021-02-09 |1438.8333333333333        |\n",
      "|2021-02-10 |1439.2333333333333        |\n",
      "|2021-02-11 |1439.0833333333333        |\n",
      "|2021-02-12 |1439.4666666666667        |\n",
      "|2021-02-13 |1666.9333333333334        |\n",
      "|2021-02-14 |1438.4166666666667        |\n",
      "|2021-02-15 |1439.0166666666667        |\n",
      "|2021-02-16 |1438.75                   |\n",
      "|2021-02-17 |1439.6666666666667        |\n",
      "|2021-02-18 |1438.8166666666666        |\n",
      "|2021-02-19 |1438.6333333333334        |\n",
      "|2021-02-20 |1439.05                   |\n",
      "|2021-02-21 |1439.0666666666666        |\n",
      "|2021-02-22 |1438.9166666666667        |\n",
      "|2021-02-23 |1439.3833333333334        |\n",
      "|2021-02-24 |1439.5166666666667        |\n",
      "|2021-02-25 |1439.7833333333333        |\n",
      "|2021-02-26 |1438.7333333333333        |\n",
      "|2021-02-27 |1438.8333333333333        |\n",
      "|2021-02-28 |1439.25                   |\n",
      "+-----------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Yellow Taxi Trip Records\\n')\n",
    "duration_trips_cal(df_yellow, 'tpep_pickup_datetime', 'tpep_dropoff_datetime').show(n=N_show, truncate=TRCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green Taxi Trip Records\n",
      "\n",
      "+-----------+--------------------------+\n",
      "|Pickup Date|Longest Duration (minutes)|\n",
      "+-----------+--------------------------+\n",
      "|2021-02-01 |84.0                      |\n",
      "|2021-02-02 |1387.1833333333334        |\n",
      "|2021-02-03 |1420.4166666666667        |\n",
      "|2021-02-04 |1429.6666666666667        |\n",
      "|2021-02-05 |1426.3666666666666        |\n",
      "|2021-02-06 |1431.35                   |\n",
      "|2021-02-07 |473.1166666666667         |\n",
      "|2021-02-08 |1424.7166666666667        |\n",
      "|2021-02-09 |1416.2333333333333        |\n",
      "|2021-02-10 |1415.35                   |\n",
      "|2021-02-11 |1434.85                   |\n",
      "|2021-02-12 |1420.6833333333334        |\n",
      "|2021-02-13 |1430.4                    |\n",
      "|2021-02-14 |1412.65                   |\n",
      "|2021-02-15 |261.78333333333336        |\n",
      "|2021-02-16 |1439.3166666666666        |\n",
      "|2021-02-17 |1416.7                    |\n",
      "|2021-02-18 |1360.25                   |\n",
      "|2021-02-19 |1419.5666666666666        |\n",
      "|2021-02-20 |1430.95                   |\n",
      "|2021-02-21 |1311.65                   |\n",
      "|2021-02-22 |1432.0833333333333        |\n",
      "|2021-02-23 |1438.4833333333333        |\n",
      "|2021-02-24 |1439.6166666666666        |\n",
      "|2021-02-25 |1437.5333333333333        |\n",
      "|2021-02-26 |1427.45                   |\n",
      "|2021-02-27 |1416.3                    |\n",
      "|2021-02-28 |1405.4666666666667        |\n",
      "+-----------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Green Taxi Trip Records\\n')\n",
    "duration_trips_cal(df_green, 'lpep_pickup_datetime', 'lpep_dropoff_datetime').show(n=N_show, truncate=TRCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FHV Trip Records\n",
      "\n",
      "+-----------+--------------------------+\n",
      "|Pickup Date|Longest Duration (minutes)|\n",
      "+-----------+--------------------------+\n",
      "|2021-02-01 |46290.0                   |\n",
      "|2021-02-02 |1390.7833333333333        |\n",
      "|2021-02-03 |1246.1666666666667        |\n",
      "|2021-02-04 |40034.88333333333         |\n",
      "|2021-02-05 |110919.0                  |\n",
      "|2021-02-06 |2752.633333333333         |\n",
      "|2021-02-07 |1306.1166666666666        |\n",
      "|2021-02-08 |9424.916666666666         |\n",
      "|2021-02-09 |1459.9833333333333        |\n",
      "|2021-02-10 |1429.85                   |\n",
      "|2021-02-11 |3219.8166666666666        |\n",
      "|2021-02-12 |4344.0                    |\n",
      "|2021-02-13 |8422.683333333332         |\n",
      "|2021-02-14 |1519.4                    |\n",
      "|2021-02-15 |14670.15                  |\n",
      "|2021-02-16 |4816.1                    |\n",
      "|2021-02-17 |4284.783333333334         |\n",
      "|2021-02-18 |2749.0333333333333        |\n",
      "|2021-02-19 |9012.15                   |\n",
      "|2021-02-20 |2701.4666666666667        |\n",
      "|2021-02-21 |1490.9833333333333        |\n",
      "|2021-02-22 |13001.533333333333        |\n",
      "|2021-02-23 |40352.0                   |\n",
      "|2021-02-24 |2767.733333333333         |\n",
      "|2021-02-25 |40489.0                   |\n",
      "|2021-02-26 |2677.5833333333335        |\n",
      "|2021-02-27 |17084.0                   |\n",
      "|2021-02-28 |15763.0                   |\n",
      "+-----------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('FHV Trip Records\\n')\n",
    "duration_trips_cal(df_fhv, 'pickup_datetime', 'dropOff_datetime').show(n=N_show, truncate=TRCT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Longest Distance (miles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00013|2021-02-01 08:01:00|2021-02-01 09:33:00|        null|        null|   null|                B00014|\n",
      "|     B00021         |2021-02-01 08:55:40|2021-02-01 09:06:20|       173.0|        82.0|   null|       B00021         |\n",
      "|     B00021         |2021-02-01 08:14:03|2021-02-01 08:28:37|       173.0|        56.0|   null|       B00021         |\n",
      "|     B00021         |2021-02-01 08:27:48|2021-02-01 08:35:45|        82.0|       129.0|   null|       B00021         |\n",
      "|              B00037|2021-02-01 08:12:50|2021-02-01 08:26:38|        null|       225.0|   null|                B00037|\n",
      "|              B00037|2021-02-01 08:00:37|2021-02-01 08:09:35|        null|        61.0|   null|                B00037|\n",
      "|              B00112|2021-02-01 08:30:25|2021-02-01 08:57:23|        null|        26.0|   null|                B00112|\n",
      "|              B00149|2021-02-01 08:43:16|2021-02-01 09:03:16|        null|        72.0|   null|                B00149|\n",
      "|              B00221|2021-02-01 08:20:45|2021-02-01 08:21:15|        null|       244.0|   null|                B00221|\n",
      "|              B00225|2021-02-01 08:23:27|2021-02-01 08:55:46|        null|       169.0|   null|                B00225|\n",
      "|              B00225|2021-02-01 08:10:38|2021-02-01 08:50:15|        null|       161.0|   null|                B02872|\n",
      "|              B00254|2021-02-01 08:05:46|2021-02-01 08:40:41|        13.0|       182.0|   null|                B00254|\n",
      "|              B00254|2021-02-01 08:14:25|2021-02-01 08:24:56|       152.0|       244.0|   null|                B02872|\n",
      "|              B00256|2021-02-01 08:30:43|2021-02-01 09:32:39|        null|        null|   null|                B00256|\n",
      "|              B00256|2021-02-01 08:39:11|2021-02-01 09:18:44|        null|        null|   null|                B00256|\n",
      "|              B00256|2021-02-01 08:33:24|2021-02-01 09:23:44|        null|        null|   null|                B00256|\n",
      "|              B00256|2021-02-01 08:05:19|2021-02-01 08:24:40|        null|        null|   null|                B00256|\n",
      "|              B00271|2021-02-01 08:04:07|2021-02-01 09:03:03|        null|       265.0|   null|                B00271|\n",
      "|              B00271|2021-02-01 08:07:13|2021-02-01 08:08:49|        null|       237.0|   null|                B00271|\n",
      "|              B00310|2021-02-01 08:11:21|2021-02-01 08:15:44|        null|       248.0|   null|                B00310|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fhv.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Top 5 Most frequent `dispatching_base_num`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Top 5 Most common location pairs (PUlocationID and DOlocationID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "494c90ffea2053e1d478862651e70463b529ab2d579abda18db8e48081cff208"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
