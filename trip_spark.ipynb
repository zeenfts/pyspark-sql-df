{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Analysis NYC TLC Trips Records Data Feb 2021\n",
    "---\n",
    "<sub>Muhammad Difagama Ivanka</sub>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(233)\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName('nyc_spark') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 20.7M    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  1 20.7M    1  326k    0     0   140k      0  0:02:31  0:00:02  0:02:29  140k\n",
      " 12 20.7M   12 2737k    0     0   841k      0  0:00:25  0:00:03  0:00:22  842k\n",
      " 17 20.7M   17 3655k    0     0   859k      0  0:00:24  0:00:04  0:00:20  859k\n",
      " 17 20.7M   17 3767k    0     0   704k      0  0:00:30  0:00:05  0:00:25  760k\n",
      " 19 20.7M   19 4068k    0     0   650k      0  0:00:32  0:00:06  0:00:26  829k\n",
      " 20 20.7M   20 4416k    0     0   605k      0  0:00:35  0:00:07  0:00:28  821k\n",
      " 22 20.7M   22 4832k    0     0   579k      0  0:00:36  0:00:08  0:00:28  411k\n",
      " 25 20.7M   25 5326k    0     0   575k      0  0:00:36  0:00:09  0:00:27  334k\n",
      " 27 20.7M   27 5763k    0     0   562k      0  0:00:37  0:00:10  0:00:27  406k\n",
      " 38 20.7M   38 8134k    0     0   722k      0  0:00:29  0:00:11  0:00:18  812k\n",
      " 45 20.7M   45 9724k    0     0   777k      0  0:00:27  0:00:12  0:00:15 1019k\n",
      " 61 20.7M   61 12.8M    0     0   993k      0  0:00:21  0:00:13  0:00:08 1696k\n",
      " 73 20.7M   73 15.3M    0     0  1101k      0  0:00:19  0:00:14  0:00:05 2075k\n",
      " 85 20.7M   85 17.8M    0     0  1195k      0  0:00:17  0:00:15  0:00:02 2494k\n",
      " 97 20.7M   97 20.2M    0     0  1275k      0  0:00:16  0:00:16 --:--:-- 2519k\n",
      "100 20.7M  100 20.7M    0     0  1292k      0  0:00:16  0:00:16 --:--:-- 2925k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      " 15 1118k   15  174k    0     0   112k      0  0:00:09  0:00:01  0:00:08  112k\n",
      "100 1118k  100 1118k    0     0   490k      0  0:00:02  0:00:02 --:--:--  492k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 10.1M    0 16384    0     0  14415      0  0:12:18  0:00:01  0:12:17 14422\n",
      " 10 10.1M   10 1070k    0     0   502k      0  0:00:20  0:00:02  0:00:18  502k\n",
      " 34 10.1M   34 3570k    0     0   895k      0  0:00:11  0:00:03  0:00:08  896k\n",
      " 34 10.1M   34 3586k    0     0   847k      0  0:00:12  0:00:04  0:00:08  847k\n",
      " 35 10.1M   35 3666k    0     0   695k      0  0:00:14  0:00:05  0:00:09  725k\n",
      " 42 10.1M   42 4380k    0     0   709k      0  0:00:14  0:00:06  0:00:08  866k\n",
      " 63 10.1M   63 6567k    0     0   920k      0  0:00:11  0:00:07  0:00:04 1099k\n",
      " 66 10.1M   66 6946k    0     0   832k      0  0:00:12  0:00:08  0:00:04  773k\n",
      " 67 10.1M   67 7026k    0     0   765k      0  0:00:13  0:00:09  0:00:04  695k\n",
      " 69 10.1M   69 7249k    0     0   708k      0  0:00:14  0:00:10  0:00:04  720k\n",
      " 71 10.1M   71 7409k    0     0   656k      0  0:00:15  0:00:11  0:00:04  592k\n",
      " 73 10.1M   73 7678k    0     0   632k      0  0:00:16  0:00:12  0:00:04  222k\n",
      " 78 10.1M   78 8165k    0     0   620k      0  0:00:16  0:00:13  0:00:03  253k\n",
      " 84 10.1M   84 8790k    0     0   621k      0  0:00:16  0:00:14  0:00:02  355k\n",
      "100 10.1M  100 10.1M    0     0   703k      0  0:00:14  0:00:14 --:--:--  692k\n"
     ]
    }
   ],
   "source": [
    "!curl https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > yellow_tripdata_2021-02.parquet\n",
    "!curl https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-02.parquet > green_tripdata_2021-02.parquet\n",
    "!curl https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2021-02.parquet > fhv_tripdata_2021-02.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = spark.read.parquet('yellow_tripdata_2021-02.parquet')\n",
    "df_green = spark.read.parquet('green_tripdata_2021-02.parquet')\n",
    "df_fhv = spark.read.parquet('fhv_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double, RatecodeID: double, store_and_fwd_flag: string, PULocationID: bigint, DOLocationID: bigint, payment_type: bigint, fare_amount: double, extra: double, mta_tax: double, tip_amount: double, tolls_amount: double, improvement_surcharge: double, total_amount: double, congestion_surcharge: double, airport_fee: double] \n",
      "\n",
      "DataFrame[VendorID: bigint, lpep_pickup_datetime: timestamp, lpep_dropoff_datetime: timestamp, store_and_fwd_flag: string, RatecodeID: double, PULocationID: bigint, DOLocationID: bigint, passenger_count: double, trip_distance: double, fare_amount: double, extra: double, mta_tax: double, tip_amount: double, tolls_amount: double, ehail_fee: int, improvement_surcharge: double, total_amount: double, payment_type: double, trip_type: double, congestion_surcharge: double] \n",
      "\n",
      "DataFrame[dispatching_base_num: string, pickup_datetime: timestamp, dropOff_datetime: timestamp, PUlocationID: double, DOlocationID: double, SR_Flag: int, Affiliated_base_number: string]\n"
     ]
    }
   ],
   "source": [
    "print(df_yellow, \"\\n\")\n",
    "print(df_green, \"\\n\")\n",
    "print(df_fhv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How many taxi trips were there on February 15?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yellow Taxi Trips on 15 February 2021\t\t\t: 43734\n",
      "Green Taxi Trips on 15 February 2021\t\t\t: 1798\n",
      "For-Hire Vehicle (FHV) Taxi Trips on 15 February 2021\t: 35523\n",
      "All Taxi Total Trips on 15 February 2021\t\t: 81055\n"
     ]
    }
   ],
   "source": [
    "def total_trips_cnt(the_df, pickup_time_col):\n",
    "    trips_cnt = the_df.where((the_df[pickup_time_col] >= \"2021-02-15 00:00:00\")\n",
    "    & (the_df[pickup_time_col] < \"2021-02-16 00:00:00\")).count()\n",
    "    return trips_cnt\n",
    "\n",
    "yel_cnt = total_trips_cnt(df_yellow, 'tpep_pickup_datetime')\n",
    "grn_cnt = total_trips_cnt(df_green, 'lpep_pickup_datetime')\n",
    "fhv_cnt = total_trips_cnt(df_fhv, 'pickup_datetime')\n",
    "\n",
    "print(f\"Yellow Taxi Trips on 15 February 2021\\t\\t\\t: {yel_cnt}\")\n",
    "print(f\"Green Taxi Trips on 15 February 2021\\t\\t\\t: {grn_cnt}\")\n",
    "print(f\"For-Hire Vehicle (FHV) Taxi Trips on 15 February 2021\\t: {fhv_cnt}\")\n",
    "print(f\"All Taxi Total Trips on 15 February 2021\\t\\t: {np.sum([yel_cnt,grn_cnt,fhv_cnt])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The longest trip for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00013|2021-02-01 08:01:00|2021-02-01 09:33:00|        null|        null|   null|                B00014|\n",
      "|     B00021         |2021-02-01 08:55:40|2021-02-01 09:06:20|       173.0|        82.0|   null|       B00021         |\n",
      "|     B00021         |2021-02-01 08:14:03|2021-02-01 08:28:37|       173.0|        56.0|   null|       B00021         |\n",
      "|     B00021         |2021-02-01 08:27:48|2021-02-01 08:35:45|        82.0|       129.0|   null|       B00021         |\n",
      "|              B00037|2021-02-01 08:12:50|2021-02-01 08:26:38|        null|       225.0|   null|                B00037|\n",
      "|              B00037|2021-02-01 08:00:37|2021-02-01 08:09:35|        null|        61.0|   null|                B00037|\n",
      "|              B00112|2021-02-01 08:30:25|2021-02-01 08:57:23|        null|        26.0|   null|                B00112|\n",
      "|              B00149|2021-02-01 08:43:16|2021-02-01 09:03:16|        null|        72.0|   null|                B00149|\n",
      "|              B00221|2021-02-01 08:20:45|2021-02-01 08:21:15|        null|       244.0|   null|                B00221|\n",
      "|              B00225|2021-02-01 08:23:27|2021-02-01 08:55:46|        null|       169.0|   null|                B00225|\n",
      "|              B00225|2021-02-01 08:10:38|2021-02-01 08:50:15|        null|       161.0|   null|                B02872|\n",
      "|              B00254|2021-02-01 08:05:46|2021-02-01 08:40:41|        13.0|       182.0|   null|                B00254|\n",
      "|              B00254|2021-02-01 08:14:25|2021-02-01 08:24:56|       152.0|       244.0|   null|                B02872|\n",
      "|              B00256|2021-02-01 08:30:43|2021-02-01 09:32:39|        null|        null|   null|                B00256|\n",
      "|              B00256|2021-02-01 08:39:11|2021-02-01 09:18:44|        null|        null|   null|                B00256|\n",
      "|              B00256|2021-02-01 08:33:24|2021-02-01 09:23:44|        null|        null|   null|                B00256|\n",
      "|              B00256|2021-02-01 08:05:19|2021-02-01 08:24:40|        null|        null|   null|                B00256|\n",
      "|              B00271|2021-02-01 08:04:07|2021-02-01 09:03:03|        null|       265.0|   null|                B00271|\n",
      "|              B00271|2021-02-01 08:07:13|2021-02-01 08:08:49|        null|       237.0|   null|                B00271|\n",
      "|              B00310|2021-02-01 08:11:21|2021-02-01 08:15:44|        null|       248.0|   null|                B00310|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Duration (minutes)\n",
    "df_yellow.withColumn(\"trip_duration\", (df_yellow.tpep_pickup_datetime)).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Top 5 Most frequent `dispatching_base_num`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Top 5 Most common location pairs (PUlocationID and DOlocationID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "494c90ffea2053e1d478862651e70463b529ab2d579abda18db8e48081cff208"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
