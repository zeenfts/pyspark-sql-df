{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Analysis NYC TLC Trips Records Data Feb 2021\n",
    "---\n",
    "<sub>Muhammad Difagama Ivanka</sub>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(233)\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName('nyc_spark') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 20.7M    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  1 20.7M    1  326k    0     0   140k      0  0:02:31  0:00:02  0:02:29  140k\n",
      " 12 20.7M   12 2737k    0     0   841k      0  0:00:25  0:00:03  0:00:22  842k\n",
      " 17 20.7M   17 3655k    0     0   859k      0  0:00:24  0:00:04  0:00:20  859k\n",
      " 17 20.7M   17 3767k    0     0   704k      0  0:00:30  0:00:05  0:00:25  760k\n",
      " 19 20.7M   19 4068k    0     0   650k      0  0:00:32  0:00:06  0:00:26  829k\n",
      " 20 20.7M   20 4416k    0     0   605k      0  0:00:35  0:00:07  0:00:28  821k\n",
      " 22 20.7M   22 4832k    0     0   579k      0  0:00:36  0:00:08  0:00:28  411k\n",
      " 25 20.7M   25 5326k    0     0   575k      0  0:00:36  0:00:09  0:00:27  334k\n",
      " 27 20.7M   27 5763k    0     0   562k      0  0:00:37  0:00:10  0:00:27  406k\n",
      " 38 20.7M   38 8134k    0     0   722k      0  0:00:29  0:00:11  0:00:18  812k\n",
      " 45 20.7M   45 9724k    0     0   777k      0  0:00:27  0:00:12  0:00:15 1019k\n",
      " 61 20.7M   61 12.8M    0     0   993k      0  0:00:21  0:00:13  0:00:08 1696k\n",
      " 73 20.7M   73 15.3M    0     0  1101k      0  0:00:19  0:00:14  0:00:05 2075k\n",
      " 85 20.7M   85 17.8M    0     0  1195k      0  0:00:17  0:00:15  0:00:02 2494k\n",
      " 97 20.7M   97 20.2M    0     0  1275k      0  0:00:16  0:00:16 --:--:-- 2519k\n",
      "100 20.7M  100 20.7M    0     0  1292k      0  0:00:16  0:00:16 --:--:-- 2925k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      " 15 1118k   15  174k    0     0   112k      0  0:00:09  0:00:01  0:00:08  112k\n",
      "100 1118k  100 1118k    0     0   490k      0  0:00:02  0:00:02 --:--:--  492k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 10.1M    0 16384    0     0  14415      0  0:12:18  0:00:01  0:12:17 14422\n",
      " 10 10.1M   10 1070k    0     0   502k      0  0:00:20  0:00:02  0:00:18  502k\n",
      " 34 10.1M   34 3570k    0     0   895k      0  0:00:11  0:00:03  0:00:08  896k\n",
      " 34 10.1M   34 3586k    0     0   847k      0  0:00:12  0:00:04  0:00:08  847k\n",
      " 35 10.1M   35 3666k    0     0   695k      0  0:00:14  0:00:05  0:00:09  725k\n",
      " 42 10.1M   42 4380k    0     0   709k      0  0:00:14  0:00:06  0:00:08  866k\n",
      " 63 10.1M   63 6567k    0     0   920k      0  0:00:11  0:00:07  0:00:04 1099k\n",
      " 66 10.1M   66 6946k    0     0   832k      0  0:00:12  0:00:08  0:00:04  773k\n",
      " 67 10.1M   67 7026k    0     0   765k      0  0:00:13  0:00:09  0:00:04  695k\n",
      " 69 10.1M   69 7249k    0     0   708k      0  0:00:14  0:00:10  0:00:04  720k\n",
      " 71 10.1M   71 7409k    0     0   656k      0  0:00:15  0:00:11  0:00:04  592k\n",
      " 73 10.1M   73 7678k    0     0   632k      0  0:00:16  0:00:12  0:00:04  222k\n",
      " 78 10.1M   78 8165k    0     0   620k      0  0:00:16  0:00:13  0:00:03  253k\n",
      " 84 10.1M   84 8790k    0     0   621k      0  0:00:16  0:00:14  0:00:02  355k\n",
      "100 10.1M  100 10.1M    0     0   703k      0  0:00:14  0:00:14 --:--:--  692k\n"
     ]
    }
   ],
   "source": [
    "!curl https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet > yellow_tripdata_2021-02.parquet\n",
    "!curl https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-02.parquet > green_tripdata_2021-02.parquet\n",
    "!curl https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2021-02.parquet > fhv_tripdata_2021-02.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = spark.read.parquet('yellow_tripdata_2021-02.parquet')\n",
    "df_green = spark.read.parquet('green_tripdata_2021-02.parquet')\n",
    "df_fhv = spark.read.parquet('fhv_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only get the February 2021 data\n",
    "def filtered_data(the_df, pickup_col: str, dropoff_col: str):\n",
    "    pickup_col = F.col(pickup_col)\n",
    "    dropoff_col = F.col(dropoff_col)\n",
    "\n",
    "    the_df = the_df.where((pickup_col >= \"2021-02-01 00:00:00\")\n",
    "    & (pickup_col< \"2021-03-01 00:00:00\"))\n",
    "    the_df = the_df.where((dropoff_col >= \"2021-02-01 00:00:00\"))\n",
    "    return the_df\n",
    "\n",
    "df_yellow = filtered_data(df_yellow, 'tpep_pickup_datetime', 'tpep_dropoff_datetime')\n",
    "df_green = filtered_data(df_green, 'lpep_pickup_datetime', 'lpep_dropoff_datetime')\n",
    "df_fhv = filtered_data(df_fhv, 'pickup_datetime', 'dropOff_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double, RatecodeID: double, store_and_fwd_flag: string, PULocationID: bigint, DOLocationID: bigint, payment_type: bigint, fare_amount: double, extra: double, mta_tax: double, tip_amount: double, tolls_amount: double, improvement_surcharge: double, total_amount: double, congestion_surcharge: double, airport_fee: double] \n",
      "\n",
      "DataFrame[VendorID: bigint, lpep_pickup_datetime: timestamp, lpep_dropoff_datetime: timestamp, store_and_fwd_flag: string, RatecodeID: double, PULocationID: bigint, DOLocationID: bigint, passenger_count: double, trip_distance: double, fare_amount: double, extra: double, mta_tax: double, tip_amount: double, tolls_amount: double, ehail_fee: int, improvement_surcharge: double, total_amount: double, payment_type: double, trip_type: double, congestion_surcharge: double] \n",
      "\n",
      "DataFrame[dispatching_base_num: string, pickup_datetime: timestamp, dropOff_datetime: timestamp, PUlocationID: double, DOlocationID: double, SR_Flag: int, Affiliated_base_number: string]\n"
     ]
    }
   ],
   "source": [
    "print(df_yellow, \"\\n\")\n",
    "print(df_green, \"\\n\")\n",
    "print(df_fhv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How many taxi trips were there on February 15?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yellow Taxi Trips on 15 February 2021\t\t\t: 43734\n",
      "Green Taxi Trips on 15 February 2021\t\t\t: 1798\n",
      "For-Hire Vehicle (FHV) Trips on 15 February 2021\t: 35523\n",
      "All Taxi Total Trips on 15 February 2021\t\t: 81055\n"
     ]
    }
   ],
   "source": [
    "def total_trips_cnt(the_df, pickup_time_col: str, beautify = True):\n",
    "    pickup_nm = F.col(pickup_time_col)\n",
    "    the_df = the_df.where((F.to_date(pickup_nm) == \"2021-02-15\"))\n",
    "\n",
    "    if beautify:\n",
    "        the_df = the_df.count()\n",
    "    else:\n",
    "        the_df = the_df.groupBy(F.to_date(pickup_nm)).count()\n",
    "        the_df = the_df.withColumnRenamed(f'to_date({pickup_time_col})', 'Pickup Date')\\\n",
    "            .withColumnRenamed('count', 'Total Trips')\n",
    "    return the_df\n",
    "\n",
    "dbn_col = F.col('dispatching_base_num')\n",
    "df_fhv_dbn = df_fhv.groupBy(dbn_col).count()\n",
    "df_fhv_dbn = df_fhv_dbn.orderBy(F.col('count').desc())\n",
    "\n",
    "yel_cnt = total_trips_cnt(df_yellow, 'tpep_pickup_datetime')\n",
    "grn_cnt = total_trips_cnt(df_green, 'lpep_pickup_datetime')\n",
    "fhv_cnt = total_trips_cnt(df_fhv, 'pickup_datetime')\n",
    "\n",
    "print(f\"Yellow Taxi Trips on 15 February 2021\\t\\t\\t: {yel_cnt}\")\n",
    "print(f\"Green Taxi Trips on 15 February 2021\\t\\t\\t: {grn_cnt}\")\n",
    "print(f\"For-Hire Vehicle (FHV) Trips on 15 February 2021\\t: {fhv_cnt}\")\n",
    "print(f\"All Taxi Total Trips on 15 February 2021\\t\\t: {np.sum([yel_cnt,grn_cnt,fhv_cnt])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yellow Taxi Trip Records\n",
      "+-----------+-----------+\n",
      "|Pickup Date|Total Trips|\n",
      "+-----------+-----------+\n",
      "| 2021-02-15|      43734|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Yellow Taxi Trip Records')\n",
    "total_trip_df_y = total_trips_cnt(df_yellow, 'tpep_pickup_datetime', False)\n",
    "total_trip_df_y.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green Taxi Trip Records\n",
      "+-----------+-----------+\n",
      "|Pickup Date|Total Trips|\n",
      "+-----------+-----------+\n",
      "| 2021-02-15|       1798|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Green Taxi Trip Records')\n",
    "total_trip_df_g = total_trips_cnt(df_green, 'lpep_pickup_datetime', False)\n",
    "total_trip_df_g.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FHV Taxi Trip Records\n",
      "+-----------+-----------+\n",
      "|Pickup Date|Total Trips|\n",
      "+-----------+-----------+\n",
      "| 2021-02-15|      35523|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('FHV Taxi Trip Records')\n",
    "total_trip_df_fhv = total_trips_cnt(df_fhv, 'pickup_datetime', False)\n",
    "total_trip_df_fhv.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The longest trip for each day"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Longest Duration (hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration_trips_cal(the_df, pickup_col: str, dropoff_col: str, type_find = 'duration',\n",
    "res_name_col = 'Longest Duration', max_col = 'trip_duration'):\n",
    "    '''\n",
    "    * the_df: dataframe.\n",
    "    * pickup_col: name of pickup datetime column.\n",
    "    * dropoff_col: name of dropoff datetime column.\n",
    "    * type_find: distance or duration.\n",
    "    * res_name_col: name of target column.\n",
    "    * max_col: name of datetime column groupby.\\n\n",
    "    -> return in hour(s) if use default value of type_find.\n",
    "    '''\n",
    "    date_col = F.to_date(pickup_col)\n",
    "    org_col = 'Pickup Date'\n",
    "    df_temp = the_df\n",
    "\n",
    "    if type_find == 'duration':\n",
    "        df_temp = the_df.withColumn(\n",
    "            max_col,\n",
    "            F.round((F.col(dropoff_col).cast('long') - F.col(pickup_col).cast('long'))/3600, 2)\n",
    "        )\n",
    "    \n",
    "    df_temp = df_temp.withColumn(max_col, F.round(F.col(max_col), 2))\n",
    "    df_temp = df_temp.groupBy(date_col).max(max_col)\n",
    "    df_temp = df_temp.withColumnRenamed(f'max({max_col})', res_name_col)\\\n",
    "        .withColumnRenamed(f'to_date({pickup_col})', org_col)\n",
    "    org_col = F.col(org_col)\n",
    "    df_temp = df_temp.orderBy(org_col.asc())\n",
    "    return df_temp\n",
    "\n",
    "N_show, TRCT = 28, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Yellow Taxi Trip Records\n",
      "+-----------+----------------+\n",
      "|Pickup Date|Longest Duration|\n",
      "+-----------+----------------+\n",
      "|2021-02-01 |23.7            |\n",
      "|2021-02-02 |23.98           |\n",
      "|2021-02-03 |23.99           |\n",
      "|2021-02-04 |24.0            |\n",
      "|2021-02-05 |23.99           |\n",
      "|2021-02-06 |23.98           |\n",
      "|2021-02-07 |23.99           |\n",
      "|2021-02-08 |23.99           |\n",
      "|2021-02-09 |23.98           |\n",
      "|2021-02-10 |23.99           |\n",
      "|2021-02-11 |23.98           |\n",
      "|2021-02-12 |23.99           |\n",
      "|2021-02-13 |27.78           |\n",
      "|2021-02-14 |23.97           |\n",
      "|2021-02-15 |23.98           |\n",
      "|2021-02-16 |23.98           |\n",
      "|2021-02-17 |23.99           |\n",
      "|2021-02-18 |23.98           |\n",
      "|2021-02-19 |23.98           |\n",
      "|2021-02-20 |23.98           |\n",
      "|2021-02-21 |23.98           |\n",
      "|2021-02-22 |23.98           |\n",
      "|2021-02-23 |23.99           |\n",
      "|2021-02-24 |23.99           |\n",
      "|2021-02-25 |24.0            |\n",
      "|2021-02-26 |23.98           |\n",
      "|2021-02-27 |23.98           |\n",
      "|2021-02-28 |23.99           |\n",
      "+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nYellow Taxi Trip Records')\n",
    "long_trip_df_y = duration_trips_cal(df_yellow, 'tpep_pickup_datetime', 'tpep_dropoff_datetime')\n",
    "long_trip_df_y.show(n=N_show, truncate=TRCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Green Taxi Trip Records\n",
      "+-----------+----------------+\n",
      "|Pickup Date|Longest Duration|\n",
      "+-----------+----------------+\n",
      "|2021-02-01 |1.4             |\n",
      "|2021-02-02 |23.12           |\n",
      "|2021-02-03 |23.67           |\n",
      "|2021-02-04 |23.83           |\n",
      "|2021-02-05 |23.77           |\n",
      "|2021-02-06 |23.86           |\n",
      "|2021-02-07 |7.89            |\n",
      "|2021-02-08 |23.75           |\n",
      "|2021-02-09 |23.6            |\n",
      "|2021-02-10 |23.59           |\n",
      "|2021-02-11 |23.91           |\n",
      "|2021-02-12 |23.68           |\n",
      "|2021-02-13 |23.84           |\n",
      "|2021-02-14 |23.54           |\n",
      "|2021-02-15 |4.36            |\n",
      "|2021-02-16 |23.99           |\n",
      "|2021-02-17 |23.61           |\n",
      "|2021-02-18 |22.67           |\n",
      "|2021-02-19 |23.66           |\n",
      "|2021-02-20 |23.85           |\n",
      "|2021-02-21 |21.86           |\n",
      "|2021-02-22 |23.87           |\n",
      "|2021-02-23 |23.97           |\n",
      "|2021-02-24 |23.99           |\n",
      "|2021-02-25 |23.96           |\n",
      "|2021-02-26 |23.79           |\n",
      "|2021-02-27 |23.61           |\n",
      "|2021-02-28 |23.42           |\n",
      "+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nGreen Taxi Trip Records')\n",
    "long_trip_df_g = duration_trips_cal(df_green, 'lpep_pickup_datetime', 'lpep_dropoff_datetime')\n",
    "long_trip_df_g.show(n=N_show, truncate=TRCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FHV Trip Records\n",
      "+-----------+----------------+\n",
      "|Pickup Date|Longest Duration|\n",
      "+-----------+----------------+\n",
      "|2021-02-01 |771.5           |\n",
      "|2021-02-02 |23.18           |\n",
      "|2021-02-03 |20.77           |\n",
      "|2021-02-04 |667.25          |\n",
      "|2021-02-05 |1848.65         |\n",
      "|2021-02-06 |45.88           |\n",
      "|2021-02-07 |21.77           |\n",
      "|2021-02-08 |157.08          |\n",
      "|2021-02-09 |24.33           |\n",
      "|2021-02-10 |23.83           |\n",
      "|2021-02-11 |53.66           |\n",
      "|2021-02-12 |72.4            |\n",
      "|2021-02-13 |140.38          |\n",
      "|2021-02-14 |25.32           |\n",
      "|2021-02-15 |244.5           |\n",
      "|2021-02-16 |80.27           |\n",
      "|2021-02-17 |71.41           |\n",
      "|2021-02-18 |45.82           |\n",
      "|2021-02-19 |150.2           |\n",
      "|2021-02-20 |45.02           |\n",
      "|2021-02-21 |24.85           |\n",
      "|2021-02-22 |216.69          |\n",
      "|2021-02-23 |672.53          |\n",
      "|2021-02-24 |46.13           |\n",
      "|2021-02-25 |674.82          |\n",
      "|2021-02-26 |44.63           |\n",
      "|2021-02-27 |284.73          |\n",
      "|2021-02-28 |262.72          |\n",
      "+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nFHV Trip Records')\n",
    "long_trip_df_fhv = duration_trips_cal(df_fhv, 'pickup_datetime', 'dropOff_datetime')\n",
    "long_trip_df_fhv.show(n=N_show, truncate=TRCT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Longest Distance (miles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Yellow Taxi Trip Records\n",
      "+-----------+----------------+\n",
      "|Pickup Date|Longest Distance|\n",
      "+-----------+----------------+\n",
      "|2021-02-01 |38.89           |\n",
      "|2021-02-02 |73.24           |\n",
      "|2021-02-03 |186079.73       |\n",
      "|2021-02-04 |82.19           |\n",
      "|2021-02-05 |91134.16        |\n",
      "|2021-02-06 |48.35           |\n",
      "|2021-02-07 |186510.67       |\n",
      "|2021-02-08 |186617.92       |\n",
      "|2021-02-09 |89416.24        |\n",
      "|2021-02-10 |116.74          |\n",
      "|2021-02-11 |54.4            |\n",
      "|2021-02-12 |34346.07        |\n",
      "|2021-02-13 |54381.65        |\n",
      "|2021-02-14 |115928.92       |\n",
      "|2021-02-15 |52.89           |\n",
      "|2021-02-16 |221188.25       |\n",
      "|2021-02-17 |95.3            |\n",
      "|2021-02-18 |140145.44       |\n",
      "|2021-02-19 |75.81           |\n",
      "|2021-02-20 |188054.03       |\n",
      "|2021-02-21 |47327.62        |\n",
      "|2021-02-22 |55.87           |\n",
      "|2021-02-23 |62.45           |\n",
      "|2021-02-24 |90073.44        |\n",
      "|2021-02-25 |48.53           |\n",
      "|2021-02-26 |90796.21        |\n",
      "|2021-02-27 |91.05           |\n",
      "|2021-02-28 |29486.5         |\n",
      "+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nYellow Taxi Trip Records')\n",
    "long_dis_df_y = duration_trips_cal(df_yellow, 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'distance',\n",
    "'Longest Distance', 'trip_distance')\n",
    "long_dis_df_y.show(n=N_show, truncate=TRCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Green Taxi Trip Records\n",
      "+-----------+----------------+\n",
      "|Pickup Date|Longest Distance|\n",
      "+-----------+----------------+\n",
      "|2021-02-01 |27.52           |\n",
      "|2021-02-02 |48.1            |\n",
      "|2021-02-03 |36.33           |\n",
      "|2021-02-04 |102620.98       |\n",
      "|2021-02-05 |36.37           |\n",
      "|2021-02-06 |38.75           |\n",
      "|2021-02-07 |90.0            |\n",
      "|2021-02-08 |5634.0          |\n",
      "|2021-02-09 |34.64           |\n",
      "|2021-02-10 |60382.7         |\n",
      "|2021-02-11 |43174.56        |\n",
      "|2021-02-12 |66659.27        |\n",
      "|2021-02-13 |15872.69        |\n",
      "|2021-02-14 |58.03           |\n",
      "|2021-02-15 |44.04           |\n",
      "|2021-02-16 |16191.56        |\n",
      "|2021-02-17 |16240.75        |\n",
      "|2021-02-18 |29501.25        |\n",
      "|2021-02-19 |34.95           |\n",
      "|2021-02-20 |4876.81         |\n",
      "|2021-02-21 |34.29           |\n",
      "|2021-02-22 |43.46           |\n",
      "|2021-02-23 |79.3            |\n",
      "|2021-02-24 |30195.95        |\n",
      "|2021-02-25 |50422.63        |\n",
      "|2021-02-26 |34.85           |\n",
      "|2021-02-27 |34.5            |\n",
      "|2021-02-28 |34.76           |\n",
      "+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nGreen Taxi Trip Records')\n",
    "long_dis_df_g = duration_trips_cal(df_green, 'lpep_pickup_datetime', 'lpep_dropoff_datetime', 'distance',\n",
    "'Longest Distance', 'trip_distance')\n",
    "long_dis_df_g.show(n=N_show, truncate=TRCT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Top 5 Most frequent `dispatching_base_num`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|dispatching_base_num|count|\n",
      "+--------------------+-----+\n",
      "|              B00856|34605|\n",
      "|              B01312|32845|\n",
      "|              B01145|30614|\n",
      "|              B02794|29998|\n",
      "|              B03016|29520|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dbn_col = F.col('dispatching_base_num')\n",
    "df_fhv_dbn = df_fhv.groupBy(dbn_col).count()\n",
    "df_fhv_dbn = df_fhv_dbn.orderBy(F.col('count').desc())\n",
    "\n",
    "df_fhv_dbn.show(n=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Top 5 Most common location pairs (PUlocationID and DOlocationID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yellow Taxi Trip Records\n",
      "+---------------------+-----+\n",
      "|PULocId_DOLocId-pairs|count|\n",
      "+---------------------+-----+\n",
      "|           {237, 236}|11378|\n",
      "|           {236, 237}| 9814|\n",
      "|           {236, 236}| 8754|\n",
      "|           {237, 237}| 7257|\n",
      "|           {264, 264}| 5677|\n",
      "+---------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def top_5_pd(the_df):\n",
    "    pld_col = 'PULocId_DOLocId-pairs'\n",
    "    the_df = the_df.withColumn(pld_col, F.struct(F.col('PULocationID'), F.col('DOLocationID')))\n",
    "    pld_col = F.col(pld_col)\n",
    "    the_df = the_df.groupBy(pld_col).count()\n",
    "    the_df = the_df.orderBy(F.col('count').desc())\n",
    "    return the_df\n",
    "\n",
    "print('Yellow Taxi Trip Records')\n",
    "df_5_pd_y = top_5_pd(df_yellow)\n",
    "df_5_pd_y.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green Taxi Trip Records\n",
      "\n",
      "+---------------------+-----+\n",
      "|PULocId_DOLocId-pairs|count|\n",
      "+---------------------+-----+\n",
      "|             {74, 75}|  986|\n",
      "|             {75, 74}|  943|\n",
      "|             {74, 74}|  636|\n",
      "|             {41, 42}|  529|\n",
      "|             {74, 42}|  491|\n",
      "+---------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Green Taxi Trip Records\\n')\n",
    "df_5_pd_g = top_5_pd(df_green)\n",
    "df_5_pd_g.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FHV Taxi Trip Records\n",
      "\n",
      "+---------------------+-----+\n",
      "|PULocId_DOLocId-pairs|count|\n",
      "+---------------------+-----+\n",
      "|           {206, 206}| 2340|\n",
      "|           {221, 206}| 2089|\n",
      "|           {129, 129}| 1879|\n",
      "|               {7, 7}| 1808|\n",
      "|           {179, 179}| 1714|\n",
      "+---------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pu_col_f = F.col('PULocationID')\n",
    "do_col_f = F.col('DOLocationID')\n",
    "df_fhv_pu_cl = df_fhv.where(pu_col_f.isNotNull())\n",
    "df_fhv_do_cl = df_fhv_pu_cl.where(do_col_f.isNotNull())\n",
    "df_fhv_do_cl = df_fhv_do_cl.withColumn('PULocationID', pu_col_f.cast('int'))\\\n",
    "    .withColumn('DOLocationID', do_col_f.cast('int'))\n",
    "\n",
    "print('FHV Taxi Trip Records\\n')\n",
    "df_5_pd_fhv = top_5_pd(df_fhv_do_cl)\n",
    "df_5_pd_fhv.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Write Result to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage, bigquery\n",
    "\n",
    "def save_as_parquet(the_df, filename) -> None:\n",
    "    the_df.write.parquet(f'{filename}.parquet')\n",
    "\n",
    "def upload_to_gcs(bucket: str, object_name: str, local_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Ref: https://cloud.google.com/storage/docs/uploading-objects#storage-upload-object-python\n",
    "    * bucket: GCS bucket name (existed)\n",
    "    * object_name: target path & file-name\n",
    "    * local_file: source path & file-name\\n\n",
    "    -> return log\n",
    "    \"\"\"\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    buckt = storage_client.bucket(bucket)\n",
    "\n",
    "    blob = buckt.blob(object_name)\n",
    "    blob.upload_from_filename(local_file)\n",
    "\n",
    "def gcs_to_bq(table_id: str, gcs_parquet_file: list) -> None:\n",
    "    \"\"\"\n",
    "    https://github.com/googleapis/python-bigquery/blob/main/samples/load_table_uri_parquet.py\n",
    "    * table_id: YOUR_GCP_PROJECT.YOUR_DATASET.YOUR_TABLE_NAME\n",
    "    * gcs_parquet_file: list of GCS file to transfer to BQ by the url \n",
    "    -> 'gs://YOUR_GCP_BUCKET_NAME/PATH_TO_THE_FILE_PARQUET'\n",
    "    \"\"\"\n",
    "    # Construct a BigQuery client object.\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # # Perform a query.\n",
    "    # QUERY = (\n",
    "    #     f'CREATE OR REPLACE EXTERNAL TABLE {table_id}'\n",
    "    #     'OPTIONS ('\n",
    "    #         'format = \"PARQUET\",'\n",
    "    #         f'uris = {gcs_parquet_file}'\n",
    "    #     ')'\n",
    "    # )\n",
    "\n",
    "    QUERY = (\n",
    "        f'LOAD DATA INTO {table_id}'\n",
    "        'OPTIONS ('\n",
    "            'format = \"PARQUET\",'\n",
    "            f'uris = {gcs_parquet_file}'\n",
    "        ')'\n",
    "    )\n",
    "\n",
    "    query_job = client.query(QUERY)  # API request\n",
    "    # rows = query_job.result()  # Waits for query to finish"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming soon! Orchestrate all the process..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "494c90ffea2053e1d478862651e70463b529ab2d579abda18db8e48081cff208"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
